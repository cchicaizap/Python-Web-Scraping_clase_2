{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Web Scraping with Beautiful Soup\n",
    "\n",
    "* * * \n",
    "\n",
    "### Icons used in this notebook\n",
    "üîî **Question**: A quick question to help you understand what's going on.<br>\n",
    "ü•ä **Challenge**: Interactive exercise. We'll work through these in the workshop!<br>\n",
    "‚ö†Ô∏è **Warning**: Heads-up about tricky stuff or common mistakes.<br>\n",
    "üí° **Tip**: How to do something a bit more efficiently or effectively.<br>\n",
    "üé¨ **Demo**: Showing off something more advanced ‚Äì so you know what Python can be used for!<br>\n",
    "\n",
    "### Learning Objectives\n",
    "1. [Reflection: To Scape Or Not To Scrape](#when)\n",
    "2. [Extracting and Parsing HTML](#extract)\n",
    "3. [Scraping the Illinois General Assembly](#scrape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='when'></a>\n",
    "\n",
    "# To Scrape Or Not To Scrape\n",
    "\n",
    "When we'd like to access data from the web, we first have to make sure if the website we are interested in offers a Web API. Platforms like Twitter, Reddit, and the New York Times offer APIs. **Check out D-Lab's [Python Web APIs](https://github.com/dlab-berkeley/Python-Web-APIs) workshop if you want to learn how to use APIs.**\n",
    "\n",
    "However, there are often cases when a Web API does not exist. In these cases, we may have to resort to web scraping, where we extract the underlying HTML from a web page, and directly obtain the information we want. There are several packages in Python we can use to accomplish these tasks. We'll focus two packages: Requests and Beautiful Soup.\n",
    "\n",
    "Our case study will be scraping information on the [state senators of Illinois](http://www.ilga.gov/senate), as well as the [list of bills](http://www.ilga.gov/senate/SenatorBills.asp?MemberID=1911&GA=98&Primary=True) each senator has sponsored. Before we get started, peruse these websites to take a look at their structure."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Installation\n",
    "\n",
    "We will use two main packages: [Requests](http://docs.python-requests.org/en/latest/user/quickstart/) and [Beautiful Soup](http://www.crummy.com/software/BeautifulSoup/bs4/doc/). Go ahead and install these packages, if you haven't already:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: requests in /workspaces/Python-Web-Scraping_clase_2/.venv/lib/python3.12/site-packages (2.32.3)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /workspaces/Python-Web-Scraping_clase_2/.venv/lib/python3.12/site-packages (from requests) (3.4.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /workspaces/Python-Web-Scraping_clase_2/.venv/lib/python3.12/site-packages (from requests) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /workspaces/Python-Web-Scraping_clase_2/.venv/lib/python3.12/site-packages (from requests) (2.3.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /workspaces/Python-Web-Scraping_clase_2/.venv/lib/python3.12/site-packages (from requests) (2025.1.31)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install requests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: beautifulsoup4 in /workspaces/Python-Web-Scraping_clase_2/.venv/lib/python3.12/site-packages (4.13.3)\n",
      "Requirement already satisfied: soupsieve>1.2 in /workspaces/Python-Web-Scraping_clase_2/.venv/lib/python3.12/site-packages (from beautifulsoup4) (2.6)\n",
      "Requirement already satisfied: typing-extensions>=4.0.0 in /workspaces/Python-Web-Scraping_clase_2/.venv/lib/python3.12/site-packages (from beautifulsoup4) (4.12.2)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install beautifulsoup4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We'll also install the `lxml` package, which helps support some of the parsing that Beautiful Soup performs:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: lxml in /workspaces/Python-Web-Scraping_clase_2/.venv/lib/python3.12/site-packages (5.3.1)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install lxml"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Import required libraries\n",
    "from bs4 import BeautifulSoup\n",
    "from datetime import datetime\n",
    "import requests\n",
    "import time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='extract'></a>\n",
    "\n",
    "# Extracting and Parsing HTML \n",
    "\n",
    "In order to succesfully scrape and analyse HTML, we'll be going through the following 4 steps:\n",
    "1. Make a GET request\n",
    "2. Parse the page with Beautiful Soup\n",
    "3. Search for HTML elements\n",
    "4. Get attributes and text of these elements"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 1: Make a GET Request to Obtain a Page's HTML\n",
    "\n",
    "We can use the Requests library to:\n",
    "\n",
    "1. Make a GET request to the page, and\n",
    "2. Read in the webpage's HTML code.\n",
    "\n",
    "The process of making a request and obtaining a result resembles that of the Web API workflow. Now, however, we're making a request directly to the website, and we're going to have to parse the HTML ourselves. This is in contrast to being provided data organized into a more straightforward `JSON` or `XML` output."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<html lang=\"en\"> \n",
      "<!-- Trigger/Open The Modal -->\n",
      "<div style=\"position: fixed; z-index: 999; top: 5; left: 600; background-color: navy; display: block\">\n",
      "<button id=\"myBtn\" style=\"color: white; background-color: navy; display: block\">Translate Website</button></div>\n",
      "<!-- The Modal -->\n",
      "<div id=\"myModal\" class=\"modal\" style=\"display: none\">\n",
      "  <!-- Modal content -->\n",
      "  <div class=\"modal-content\">\n",
      "      <div class=\"modal-header\"><h3>\n",
      "    <span class=\"close\">&times;</span></h3></div>    \n",
      "    <p>The Illinois General Assembly offers the Google Translate¬ô service for visitor convenience. In no way should it be considered accurate as to the translation of any content herein.</p>\n",
      "    <p>Visitors of the Illinois General Assembly website are encouraged to use other translation services available on the internet.</p>\n",
      "    <p>The English language version is always the official and authoritative version of this website.</p>\n",
      "    <p>NOTE: To return to the original English language version, se\n"
     ]
    }
   ],
   "source": [
    "# Make a GET request\n",
    "req = requests.get('http://www.ilga.gov/senate/default.asp')\n",
    "# Read the content of the server‚Äôs response\n",
    "src = req.text\n",
    "# View some output\n",
    "print(src[:1000])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 2: Parse the Page with Beautiful Soup\n",
    "\n",
    "Now, we use the `BeautifulSoup` function to parse the reponse into an HTML tree. This returns an object (called a **soup object**) which contains all of the HTML in the original document.\n",
    "\n",
    "If you run into an error about a parser library, make sure you've installed the `lxml` package to provide Beautiful Soup with the necessary parsing tools."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<html lang=\"en\">\n",
      " <!-- Trigger/Open The Modal -->\n",
      " <body>\n",
      "  <div style=\"position: fixed; z-index: 999; top: 5; left: 600; background-color: navy; display: block\">\n",
      "   <button id=\"myBtn\" style=\"color: white; background-color: navy; display: block\">\n",
      "    Translate Website\n",
      "   </button>\n",
      "  </div>\n",
      "  <!-- The Modal -->\n",
      "  <div class=\"modal\" id=\"myModal\" style=\"display: none\">\n",
      "   <!-- Modal content -->\n",
      "   <div class=\"modal-content\">\n",
      "    <div class=\"modal-header\">\n",
      "     <h3>\n",
      "      <span class=\"close\">\n",
      "       √ó\n",
      "      </span>\n",
      "     </h3>\n",
      "    </div>\n",
      "    <p>\n",
      "     The Illinois General Assembly offers the Google Translate¬ô service for visitor convenience. In no way should it be considered accurate as to the translation of any content herein.\n",
      "    </p>\n",
      "    <p>\n",
      "     Visitors of the Illinois General Assembly website are encouraged to use other translation services available on the internet.\n",
      "    </p>\n",
      "    <p>\n",
      "     The English language version is always the official and authoritative version of this website.\n",
      "   \n"
     ]
    }
   ],
   "source": [
    "# Parse the response into an HTML tree\n",
    "soup = BeautifulSoup(src, 'lxml')\n",
    "# Take a look\n",
    "print(soup.prettify()[:1000])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The output looks pretty similar to the above, but now it's organized in a `soup` object which allows us to more easily traverse the page."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 3: Search for HTML Elements\n",
    "\n",
    "Beautiful Soup has a number of functions to find useful components on a page. Beautiful Soup lets you find elements by their:\n",
    "\n",
    "1. HTML tags\n",
    "2. HTML Attributes\n",
    "3. CSS Selectors\n",
    "\n",
    "Let's search first for **HTML tags**. \n",
    "\n",
    "The function `find_all` searches the `soup` tree to find all the elements with an a particular HTML tag, and returns all of those elements.\n",
    "\n",
    "What does the example below do?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[<a class=\"goog-logo-link\" href=\"https://translate.google.com\" target=\"_blank\"><img alt=\"Google Translate\" height=\"14\" src=\"https://www.gstatic.com/images/branding/googlelogo/1x/googlelogo_color_42x16dp.png\" style=\"padding-right: 3px;\" width=\"37\"/>Translate</a>, <a href=\"/default.asp\"><img alt=\"Illinois General Assembly\" border=\"0\" height=\"49\" src=\"/images/logo_sm.gif\" width=\"462\"/></a>, <a class=\"mainmenu\" href=\"/\">Home</a>, <a class=\"mainmenu\" href=\"/legislation/\" onblur=\"HM_f_PopDown('elMenu1')\" onfocus=\"HM_f_PopUp('elMenu1',event)\" onmouseout=\"HM_f_PopDown('elMenu1')\" onmouseover=\"HM_f_PopUp('elMenu1',event)\">Legislation &amp; Laws</a>, <a class=\"mainmenu\" href=\"/senate/\" onblur=\"HM_f_PopDown('elMenu3')\" onfocus=\"HM_f_PopUp('elMenu3',event)\" onmouseout=\"HM_f_PopDown('elMenu3')\" onmouseover=\"HM_f_PopUp('elMenu3',event)\">Senate</a>, <a class=\"mainmenu\" href=\"/house/\" onblur=\"HM_f_PopDown('elMenu2')\" onfocus=\"HM_f_PopUp('elMenu2',event)\" onmouseout=\"HM_f_PopDown('elMenu2')\" onmouseover=\"HM_f_PopUp('elMenu2',event)\">House</a>, <a class=\"mainmenu\" href=\"/mylegislation/\" onblur=\"HM_f_PopDown('elMenu4')\" onfocus=\"HM_f_PopUp('elMenu4',event)\" onmouseout=\"HM_f_PopDown('elMenu4')\" onmouseover=\"HM_f_PopUp('elMenu4',event)\">My Legislation</a>, <a class=\"mainmenu\" href=\"/sitemap.asp\">Site Map</a>, <a class=\"sidemenu\" href=\"/senate/default.asp\">¬†¬†Members¬†¬†</a>, <a class=\"sidemenu\" href=\"/senate/committees/default.asp\">¬†¬†Committees¬†¬†</a>]\n"
     ]
    }
   ],
   "source": [
    "# Find all elements with a certain tag\n",
    "a_tags = soup.find_all(\"a\")\n",
    "print(a_tags[:10])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Because `find_all()` is the most popular method in the Beautiful Soup search API, you can use a shortcut for it. If you treat the BeautifulSoup object as though it were a function, then it‚Äôs the same as calling `find_all()` on that object. \n",
    "\n",
    "These two lines of code are equivalent:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<a class=\"goog-logo-link\" href=\"https://translate.google.com\" target=\"_blank\"><img alt=\"Google Translate\" height=\"14\" src=\"https://www.gstatic.com/images/branding/googlelogo/1x/googlelogo_color_42x16dp.png\" style=\"padding-right: 3px;\" width=\"37\"/>Translate</a>\n",
      "<a class=\"goog-logo-link\" href=\"https://translate.google.com\" target=\"_blank\"><img alt=\"Google Translate\" height=\"14\" src=\"https://www.gstatic.com/images/branding/googlelogo/1x/googlelogo_color_42x16dp.png\" style=\"padding-right: 3px;\" width=\"37\"/>Translate</a>\n"
     ]
    }
   ],
   "source": [
    "a_tags = soup.find_all(\"a\")\n",
    "a_tags_alt = soup(\"a\")\n",
    "print(a_tags[0])\n",
    "print(a_tags_alt[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "How many links did we obtain?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "213\n"
     ]
    }
   ],
   "source": [
    "print(len(a_tags))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "That's a lot! Many elements on a page will have the same HTML tag. For instance, if you search for everything with the `a` tag, you're likely to get more hits, many of which you might not want. Remember, the `a` tag defines a hyperlink, so you'll usually find many on any given page.\n",
    "\n",
    "What if we wanted to search for HTML tags with certain attributes, such as particular CSS classes? \n",
    "\n",
    "We can do this by adding an additional argument to the `find_all`. In the example below, we are finding all the `a` tags, and then filtering those with `class_=\"sidemenu\"`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<a class=\"sidemenu\" href=\"/senate/default.asp\">¬†¬†Members¬†¬†</a>,\n",
       " <a class=\"sidemenu\" href=\"/senate/committees/default.asp\">¬†¬†Committees¬†¬†</a>,\n",
       " <a class=\"sidemenu\" href=\"/senate/schedules/default.asp\">¬†¬†Schedules¬†¬†</a>,\n",
       " <a class=\"sidemenu\" href=\"/senate/journals/default.asp\">¬†¬†Journals¬†¬†</a>,\n",
       " <a class=\"sidemenu\" href=\"/senate/transcripts/default.asp\">¬†¬†Transcripts¬†¬†</a>]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get only the 'a' tags in 'sidemenu' class\n",
    "side_menus = soup(\"a\", class_=\"sidemenu\")\n",
    "side_menus[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A more efficient way to search for elements on a website is via a **CSS selector**. For this we have to use a different method called `select()`. Just pass a string into the `.select()` to get all elements with that string as a valid CSS selector.\n",
    "\n",
    "In the example above, we can use `\"a.sidemenu\"` as a CSS selector, which returns all `a` tags with class `sidemenu`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<a class=\"sidemenu\" href=\"/senate/default.asp\">¬†¬†Members¬†¬†</a>,\n",
       " <a class=\"sidemenu\" href=\"/senate/committees/default.asp\">¬†¬†Committees¬†¬†</a>,\n",
       " <a class=\"sidemenu\" href=\"/senate/schedules/default.asp\">¬†¬†Schedules¬†¬†</a>,\n",
       " <a class=\"sidemenu\" href=\"/senate/journals/default.asp\">¬†¬†Journals¬†¬†</a>,\n",
       " <a class=\"sidemenu\" href=\"/senate/transcripts/default.asp\">¬†¬†Transcripts¬†¬†</a>]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get elements with \"a.sidemenu\" CSS Selector.\n",
    "selected = soup.select(\"a.sidemenu\")\n",
    "selected[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ü•ä Challenge: Find All\n",
    "\n",
    "Use BeautifulSoup to find all the `a` elements with class `mainmenu`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<a class=\"mainmenu\" href=\"/\">Home</a>,\n",
       " <a class=\"mainmenu\" href=\"/legislation/\" onblur=\"HM_f_PopDown('elMenu1')\" onfocus=\"HM_f_PopUp('elMenu1',event)\" onmouseout=\"HM_f_PopDown('elMenu1')\" onmouseover=\"HM_f_PopUp('elMenu1',event)\">Legislation &amp; Laws</a>,\n",
       " <a class=\"mainmenu\" href=\"/senate/\" onblur=\"HM_f_PopDown('elMenu3')\" onfocus=\"HM_f_PopUp('elMenu3',event)\" onmouseout=\"HM_f_PopDown('elMenu3')\" onmouseover=\"HM_f_PopUp('elMenu3',event)\">Senate</a>,\n",
       " <a class=\"mainmenu\" href=\"/house/\" onblur=\"HM_f_PopDown('elMenu2')\" onfocus=\"HM_f_PopUp('elMenu2',event)\" onmouseout=\"HM_f_PopDown('elMenu2')\" onmouseover=\"HM_f_PopUp('elMenu2',event)\">House</a>,\n",
       " <a class=\"mainmenu\" href=\"/mylegislation/\" onblur=\"HM_f_PopDown('elMenu4')\" onfocus=\"HM_f_PopUp('elMenu4',event)\" onmouseout=\"HM_f_PopDown('elMenu4')\" onmouseover=\"HM_f_PopUp('elMenu4',event)\">My Legislation</a>]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# YOUR CODE HERE\n",
    "main_menus = soup.select(\"a.mainmenu\")\n",
    "main_menus[:5]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 4: Get Attributes and Text of Elements\n",
    "\n",
    "Once we identify elements, we want the access information in that element. Usually, this means two things:\n",
    "\n",
    "1. Text\n",
    "2. Attributes\n",
    "\n",
    "Getting the text inside an element is easy. All we have to do is use the `text` member of a `tag` object:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<a class=\"sidemenu\" href=\"/senate/default.asp\">¬†¬†Members¬†¬†</a>\n",
      "Class:  <class 'bs4.element.Tag'>\n"
     ]
    }
   ],
   "source": [
    "# Get all sidemenu links as a list\n",
    "side_menu_links = soup.select(\"a.sidemenu\")\n",
    "\n",
    "# Examine the first link\n",
    "first_link = side_menu_links[0]\n",
    "print(first_link)\n",
    "\n",
    "# What class is this variable?\n",
    "print('Class: ', type(first_link))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It's a Beautiful Soup tag! This means it has a `text` member:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "¬†¬†Members¬†¬†\n"
     ]
    }
   ],
   "source": [
    "print(first_link.text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sometimes we want the value of certain attributes. This is particularly relevant for `a` tags, or links, where the `href` attribute tells us where the link goes.\n",
    "\n",
    "üí° **Tip**: You can access a tag‚Äôs attributes by treating the tag like a dictionary:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/senate/default.asp\n"
     ]
    }
   ],
   "source": [
    "print(first_link['href'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ü•ä Challenge: Extract specific attributes\n",
    "\n",
    "Extract all `href` attributes for each `mainmenu` URL."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/\n",
      "/legislation/\n",
      "/senate/\n",
      "/house/\n",
      "/mylegislation/\n",
      "/sitemap.asp\n",
      "/\n",
      "/legislation/\n"
     ]
    }
   ],
   "source": [
    "# YOUR CODE HERE\n",
    "for link in main_menus:\n",
    "    print(link['href'])\n",
    "\n",
    "for i in range(2):\n",
    "    print(main_menus[i]['href'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='scrape'></a>\n",
    "\n",
    "# Scraping the Illinois General Assembly\n",
    "\n",
    "Believe it or not, those are really the fundamental tools you need to scrape a website. Once you spend more time familiarizing yourself with HTML and CSS, then it's simply a matter of understanding the structure of a particular website and intelligently applying the tools of Beautiful Soup and Python.\n",
    "\n",
    "Let's apply these skills to scrape the [Illinois 98th General Assembly](http://www.ilga.gov/senate/default.asp?GA=98).\n",
    "\n",
    "Specifically, our goal is to scrape information on each senator, including their name, district, and party."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Scrape and Soup the Webpage\n",
    "\n",
    "Let's scrape and parse the webpage, using the tools we learned in the previous section."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Make a GET request\n",
    "req = requests.get('http://www.ilga.gov/senate/default.asp?GA=98')\n",
    "# Read the content of the server‚Äôs response\n",
    "src = req.text\n",
    "# Soup it\n",
    "soup = BeautifulSoup(src, \"lxml\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Search for the Table Elements\n",
    "\n",
    "Our goal is to obtain the elements in the table on the webpage. Remember: rows are identified by the `tr` tag. Let's use `find_all` to obtain these elements."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "73"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get all table row elements\n",
    "rows = soup.find_all(\"tr\")\n",
    "len(rows)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "‚ö†Ô∏è **Warning**: Keep in mind: `find_all` gets *all* the elements with the `tr` tag. We only want some of them. If we use the 'Inspect' function in Google Chrome and look carefully, then we can use some CSS selectors to get just the rows we're interested in. Specifically, we want the inner rows of the table:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<tr><td colspan=\"5\">\n",
      "<span class=\"heading\">Illinois State Senators</span>\n",
      "<span class=\"italics\">¬†¬†98th  General Assembly</span><br/>\n",
      "<!-- 3/2/09 temp comment out until fixed for GA specific-->\n",
      "<!-- add 97th ga currently no info -->\n",
      "<a href=\"98GA_Senate_Leadership.pdf\">Leadership</a>¬†<a href=\"98th_Senate_Officers.pdf\">Officers</a>¬†<a href=\"98GA_Senate_Seating_Chart.pdf\">Senate Seating Chart</a>¬†¬†<span class=\"content\"><b>Democrats:</b> 40¬†¬† <b>Republicans:</b> 19</span><br/>\n",
      "</td></tr> \n",
      "\n",
      "<tr>\n",
      "<td class=\"header\" width=\"45%\"><a class=\"filetab\" href=\"javascript:Sort('LastName','',98);\" title=\"Sort by Senator\">Senator</a></td>\n",
      "<td align=\"center\" class=\"header\" width=\"15%\">Bills</td>\n",
      "<td align=\"center\" class=\"header\" width=\"10%\">Committees</td>\n",
      "<td align=\"center\" class=\"header\" width=\"15%\"><a class=\"filetab\" href=\"javascript:Sort('DistrictNumber','',98);\" title=\"Sort by District\">District</a></td>\n",
      "<td align=\"center\" class=\"header\" width=\"15%\"><a class=\"filetab\" href=\"javascript:Sort('Party','',98);\" title=\"Sort by Party\">Party</a></td>\n",
      "</tr> \n",
      "\n",
      "<tr><td bgcolor=\"white\" class=\"detail\" width=\"40%\"><a class=\"notranslate\" href=\"/senate/Senator.asp?GA=98&amp;MemberID=1911\">Pamela J. Althoff</a></td><td align=\"center\" bgcolor=\"white\" class=\"detail\" width=\"15%\"><a href=\"SenatorBills.asp?GA=98&amp;MemberID=1911\">Bills</a></td><td align=\"center\" bgcolor=\"white\" class=\"detail\" width=\"15%\"><a href=\"SenCommittees.asp?GA=98&amp;MemberID=1911\">Committees</a></td><td align=\"center\" bgcolor=\"white\" class=\"detail\" width=\"15%\">32</td><td align=\"center\" bgcolor=\"white\" class=\"detail\" width=\"15%\">R</td></tr> \n",
      "\n",
      "<tr><td bgcolor=\"EBEBEB\" class=\"detail\" width=\"40%\"><a class=\"notranslate\" href=\"/senate/Senator.asp?GA=98&amp;MemberID=2018\">Jason A. Barickman</a></td><td align=\"center\" bgcolor=\"EBEBEB\" class=\"detail\" width=\"15%\"><a href=\"SenatorBills.asp?GA=98&amp;MemberID=2018\">Bills</a></td><td align=\"center\" bgcolor=\"EBEBEB\" class=\"detail\" width=\"15%\"><a href=\"SenCommittees.asp?GA=98&amp;MemberID=2018\">Committees</a></td><td align=\"center\" bgcolor=\"EBEBEB\" class=\"detail\" width=\"15%\">53</td><td align=\"center\" bgcolor=\"EBEBEB\" class=\"detail\" width=\"15%\">R</td></tr> \n",
      "\n",
      "<tr><td bgcolor=\"white\" class=\"detail\" width=\"40%\"><a class=\"notranslate\" href=\"/senate/Senator.asp?GA=98&amp;MemberID=2272\">Scott M Bennett</a></td><td align=\"center\" bgcolor=\"white\" class=\"detail\" width=\"15%\"><a href=\"SenatorBills.asp?GA=98&amp;MemberID=2272\">Bills</a></td><td align=\"center\" bgcolor=\"white\" class=\"detail\" width=\"15%\"><a href=\"SenCommittees.asp?GA=98&amp;MemberID=2272\">Committees</a></td><td align=\"center\" bgcolor=\"white\" class=\"detail\" width=\"15%\">52</td><td align=\"center\" bgcolor=\"white\" class=\"detail\" width=\"15%\">D</td></tr> \n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Returns every ‚Äòtr tr tr‚Äô css selector in the page\n",
    "rows = soup.select('tr tr tr')\n",
    "\n",
    "for row in rows[:5]:\n",
    "    print(row, '\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It looks like we want everything after the first two rows. Let's work with a single row to start, and build our loop from there."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<tr>\n",
      " <td bgcolor=\"white\" class=\"detail\" width=\"40%\">\n",
      "  <a class=\"notranslate\" href=\"/senate/Senator.asp?GA=98&amp;MemberID=1911\">\n",
      "   Pamela J. Althoff\n",
      "  </a>\n",
      " </td>\n",
      " <td align=\"center\" bgcolor=\"white\" class=\"detail\" width=\"15%\">\n",
      "  <a href=\"SenatorBills.asp?GA=98&amp;MemberID=1911\">\n",
      "   Bills\n",
      "  </a>\n",
      " </td>\n",
      " <td align=\"center\" bgcolor=\"white\" class=\"detail\" width=\"15%\">\n",
      "  <a href=\"SenCommittees.asp?GA=98&amp;MemberID=1911\">\n",
      "   Committees\n",
      "  </a>\n",
      " </td>\n",
      " <td align=\"center\" bgcolor=\"white\" class=\"detail\" width=\"15%\">\n",
      "  32\n",
      " </td>\n",
      " <td align=\"center\" bgcolor=\"white\" class=\"detail\" width=\"15%\">\n",
      "  R\n",
      " </td>\n",
      "</tr>\n",
      "\n"
     ]
    }
   ],
   "source": [
    "example_row = rows[2]\n",
    "print(example_row.prettify())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's break this row down into its component cells/columns using the `select` method with CSS selectors. Looking closely at the HTML, there are a couple of ways we could do this.\n",
    "\n",
    "* We could identify the cells by their tag `td`.\n",
    "* We could use the the class name `.detail`.\n",
    "* We could combine both and use the selector `td.detail`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<td bgcolor=\"white\" class=\"detail\" width=\"40%\"><a class=\"notranslate\" href=\"/senate/Senator.asp?GA=98&amp;MemberID=1911\">Pamela J. Althoff</a></td>\n",
      "<td align=\"center\" bgcolor=\"white\" class=\"detail\" width=\"15%\"><a href=\"SenatorBills.asp?GA=98&amp;MemberID=1911\">Bills</a></td>\n",
      "<td align=\"center\" bgcolor=\"white\" class=\"detail\" width=\"15%\"><a href=\"SenCommittees.asp?GA=98&amp;MemberID=1911\">Committees</a></td>\n",
      "<td align=\"center\" bgcolor=\"white\" class=\"detail\" width=\"15%\">32</td>\n",
      "<td align=\"center\" bgcolor=\"white\" class=\"detail\" width=\"15%\">R</td>\n",
      "\n",
      "<td bgcolor=\"white\" class=\"detail\" width=\"40%\"><a class=\"notranslate\" href=\"/senate/Senator.asp?GA=98&amp;MemberID=1911\">Pamela J. Althoff</a></td>\n",
      "<td align=\"center\" bgcolor=\"white\" class=\"detail\" width=\"15%\"><a href=\"SenatorBills.asp?GA=98&amp;MemberID=1911\">Bills</a></td>\n",
      "<td align=\"center\" bgcolor=\"white\" class=\"detail\" width=\"15%\"><a href=\"SenCommittees.asp?GA=98&amp;MemberID=1911\">Committees</a></td>\n",
      "<td align=\"center\" bgcolor=\"white\" class=\"detail\" width=\"15%\">32</td>\n",
      "<td align=\"center\" bgcolor=\"white\" class=\"detail\" width=\"15%\">R</td>\n",
      "\n",
      "<td bgcolor=\"white\" class=\"detail\" width=\"40%\"><a class=\"notranslate\" href=\"/senate/Senator.asp?GA=98&amp;MemberID=1911\">Pamela J. Althoff</a></td>\n",
      "<td align=\"center\" bgcolor=\"white\" class=\"detail\" width=\"15%\"><a href=\"SenatorBills.asp?GA=98&amp;MemberID=1911\">Bills</a></td>\n",
      "<td align=\"center\" bgcolor=\"white\" class=\"detail\" width=\"15%\"><a href=\"SenCommittees.asp?GA=98&amp;MemberID=1911\">Committees</a></td>\n",
      "<td align=\"center\" bgcolor=\"white\" class=\"detail\" width=\"15%\">32</td>\n",
      "<td align=\"center\" bgcolor=\"white\" class=\"detail\" width=\"15%\">R</td>\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for cell in example_row.select('td'):\n",
    "    print(cell)\n",
    "print()\n",
    "\n",
    "for cell in example_row.select('.detail'):\n",
    "    print(cell)\n",
    "print()\n",
    "\n",
    "for cell in example_row.select('td.detail'):\n",
    "    print(cell)\n",
    "print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can confirm that these are all the same."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "assert example_row.select('td') == example_row.select('.detail') == example_row.select('td.detail')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's use the selector `td.detail` to be as specific as possible."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<td bgcolor=\"white\" class=\"detail\" width=\"40%\"><a class=\"notranslate\" href=\"/senate/Senator.asp?GA=98&amp;MemberID=1911\">Pamela J. Althoff</a></td>,\n",
       " <td align=\"center\" bgcolor=\"white\" class=\"detail\" width=\"15%\"><a href=\"SenatorBills.asp?GA=98&amp;MemberID=1911\">Bills</a></td>,\n",
       " <td align=\"center\" bgcolor=\"white\" class=\"detail\" width=\"15%\"><a href=\"SenCommittees.asp?GA=98&amp;MemberID=1911\">Committees</a></td>,\n",
       " <td align=\"center\" bgcolor=\"white\" class=\"detail\" width=\"15%\">32</td>,\n",
       " <td align=\"center\" bgcolor=\"white\" class=\"detail\" width=\"15%\">R</td>]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Select only those 'td' tags with class 'detail' \n",
    "detail_cells = example_row.select('td.detail')\n",
    "detail_cells"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Most of the time, we're interested in the actual **text** of a website, not its tags. Recall that to get the text of an HTML element, we use the `text` member:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Pamela J. Althoff', 'Bills', 'Committees', '32', 'R']\n"
     ]
    }
   ],
   "source": [
    "# Keep only the text in each of those cells\n",
    "row_data = [cell.text for cell in detail_cells]\n",
    "\n",
    "print(row_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Looks good! Now we just use our basic Python knowledge to get the elements of this list that we want. Remember, we want the senator's name, their district, and their party."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pamela J. Althoff\n",
      "32\n",
      "R\n"
     ]
    }
   ],
   "source": [
    "print(row_data[0]) # Name\n",
    "print(row_data[3]) # District\n",
    "print(row_data[4]) # Party"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Desaci√©ndonos de las filas basura\n",
    "\n",
    "Vimos que en el principio que no todas las files que se obtienen corresponden a un Senador. Vamos a necesitar hacer un poco de limpieza antes de seguir. Veamos algunos ejemplos:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fila 0:\n",
      " <tr><td colspan=\"5\">\n",
      "<span class=\"heading\">Illinois State Senators</span>\n",
      "<span class=\"italics\">¬†¬†98th  General Assembly</span><br/>\n",
      "<!-- 3/2/09 temp comment out until fixed for GA specific-->\n",
      "<!-- add 97th ga currently no info -->\n",
      "<a href=\"98GA_Senate_Leadership.pdf\">Leadership</a>¬†<a href=\"98th_Senate_Officers.pdf\">Officers</a>¬†<a href=\"98GA_Senate_Seating_Chart.pdf\">Senate Seating Chart</a>¬†¬†<span class=\"content\"><b>Democrats:</b> 40¬†¬† <b>Republicans:</b> 19</span><br/>\n",
      "</td></tr> \n",
      "\n",
      "Fila 1:\n",
      " <tr>\n",
      "<td class=\"header\" width=\"45%\"><a class=\"filetab\" href=\"javascript:Sort('LastName','',98);\" title=\"Sort by Senator\">Senator</a></td>\n",
      "<td align=\"center\" class=\"header\" width=\"15%\">Bills</td>\n",
      "<td align=\"center\" class=\"header\" width=\"10%\">Committees</td>\n",
      "<td align=\"center\" class=\"header\" width=\"15%\"><a class=\"filetab\" href=\"javascript:Sort('DistrictNumber','',98);\" title=\"Sort by District\">District</a></td>\n",
      "<td align=\"center\" class=\"header\" width=\"15%\"><a class=\"filetab\" href=\"javascript:Sort('Party','',98);\" title=\"Sort by Party\">Party</a></td>\n",
      "</tr> \n",
      "\n",
      "√öltima fila:\n",
      " <tr>\n",
      "<td align=\"left\" class=\"footer\" width=\"107\">¬†¬†<img alt=\"Legislative Information System logo\" height=\"45\" src=\"/images/lislogo.jpg\" width=\"100\"/></td>\n",
      "<td align=\"\" class=\"footer\" valign=\"top\" width=\"100%\">This site is maintained for the Illinois General Assembly \n",
      "by the<br/>Legislative Information System, 705 Stratton Building, Springfield, Illinois 62706<br/>\n",
      "<a class=\"links\" href=\"mailto:webmaster@ilga.gov?subject=Email from ILGA Web\" style=\"font-size:8px\">\n",
      "      Contact ILGA Webmaster</a>\n",
      "</td>\n",
      "</tr>\n"
     ]
    }
   ],
   "source": [
    "print('Fila 0:\\n', rows[0], '\\n')\n",
    "print('Fila 1:\\n', rows[1], '\\n')\n",
    "print('√öltima fila:\\n', rows[-1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cuando utilizamos el bucle \"for\", nosotros solo queremos aplicarlo en las filas m√°s relevantes. Por lo que necesitamos filtrar las filas irrelevantes. La manera de hacer esto es comparando algunas de las filas que queremos, para ver que las hace diferentes, y luego utilizar esa informaci√≥n en un condicional.\n",
    "\n",
    "Como lo puedes imaginar, hay muchas maneras de hacer esto, y va a depender del sitio web. Vamos a mostrar algunas maneras aqu√≠ para darte una idea de como hacerlo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "11\n",
      "5\n",
      "5\n"
     ]
    }
   ],
   "source": [
    "# Bad rows\n",
    "print(len(rows[0]))\n",
    "print(len(rows[1]))\n",
    "\n",
    "# Good rows\n",
    "print(len(rows[2]))\n",
    "print(len(rows[3]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tal vez las filas buenas tienen una longitud de 5. Revisemos:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<tr><td bgcolor=\"white\" class=\"detail\" width=\"40%\"><a class=\"notranslate\" href=\"/senate/Senator.asp?GA=98&amp;MemberID=1911\">Pamela J. Althoff</a></td><td align=\"center\" bgcolor=\"white\" class=\"detail\" width=\"15%\"><a href=\"SenatorBills.asp?GA=98&amp;MemberID=1911\">Bills</a></td><td align=\"center\" bgcolor=\"white\" class=\"detail\" width=\"15%\"><a href=\"SenCommittees.asp?GA=98&amp;MemberID=1911\">Committees</a></td><td align=\"center\" bgcolor=\"white\" class=\"detail\" width=\"15%\">32</td><td align=\"center\" bgcolor=\"white\" class=\"detail\" width=\"15%\">R</td></tr> \n",
      "\n",
      "<tr><td bgcolor=\"white\" class=\"detail\" width=\"40%\"><a class=\"notranslate\" href=\"/senate/Senator.asp?GA=98&amp;MemberID=2035\">Patricia Van Pelt</a></td><td align=\"center\" bgcolor=\"white\" class=\"detail\" width=\"15%\"><a href=\"SenatorBills.asp?GA=98&amp;MemberID=2035\">Bills</a></td><td align=\"center\" bgcolor=\"white\" class=\"detail\" width=\"15%\"><a href=\"SenCommittees.asp?GA=98&amp;MemberID=2035\">Committees</a></td><td align=\"center\" bgcolor=\"white\" class=\"detail\" width=\"15%\">5</td><td align=\"center\" bgcolor=\"white\" class=\"detail\" width=\"15%\">D</td></tr> \n",
      "\n",
      "<tr>\n",
      "<td align=\"left\" class=\"footer\" width=\"107\">¬†¬†<img alt=\"Legislative Information System logo\" height=\"45\" src=\"/images/lislogo.jpg\" width=\"100\"/></td>\n",
      "<td align=\"\" class=\"footer\" valign=\"top\" width=\"100%\">This site is maintained for the Illinois General Assembly \n",
      "by the<br/>Legislative Information System, 705 Stratton Building, Springfield, Illinois 62706<br/>\n",
      "<a class=\"links\" href=\"mailto:webmaster@ilga.gov?subject=Email from ILGA Web\" style=\"font-size:8px\">\n",
      "      Contact ILGA Webmaster</a>\n",
      "</td>\n",
      "</tr>\n"
     ]
    }
   ],
   "source": [
    "good_rows = [row for row in rows if len(row) == 5]\n",
    "\n",
    "# Let's check some rows\n",
    "print(good_rows[0], '\\n')\n",
    "print(good_rows[-2], '\\n')\n",
    "print(good_rows[-1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Encontramos una fila footer en nuestra lista que nos gustar√≠a evitar. Vamos a intentar otra cosa:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<td bgcolor=\"white\" class=\"detail\" width=\"40%\"><a class=\"notranslate\" href=\"/senate/Senator.asp?GA=98&amp;MemberID=1911\">Pamela J. Althoff</a></td>,\n",
       " <td align=\"center\" bgcolor=\"white\" class=\"detail\" width=\"15%\"><a href=\"SenatorBills.asp?GA=98&amp;MemberID=1911\">Bills</a></td>,\n",
       " <td align=\"center\" bgcolor=\"white\" class=\"detail\" width=\"15%\"><a href=\"SenCommittees.asp?GA=98&amp;MemberID=1911\">Committees</a></td>,\n",
       " <td align=\"center\" bgcolor=\"white\" class=\"detail\" width=\"15%\">32</td>,\n",
       " <td align=\"center\" bgcolor=\"white\" class=\"detail\" width=\"15%\">R</td>]"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rows[2].select('td.detail') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[] \n",
      "\n",
      "[<td bgcolor=\"EBEBEB\" class=\"detail\" width=\"40%\"><a class=\"notranslate\" href=\"/senate/Senator.asp?GA=98&amp;MemberID=2022\">Jennifer Bertino-Tarrant</a></td>, <td align=\"center\" bgcolor=\"EBEBEB\" class=\"detail\" width=\"15%\"><a href=\"SenatorBills.asp?GA=98&amp;MemberID=2022\">Bills</a></td>, <td align=\"center\" bgcolor=\"EBEBEB\" class=\"detail\" width=\"15%\"><a href=\"SenCommittees.asp?GA=98&amp;MemberID=2022\">Committees</a></td>, <td align=\"center\" bgcolor=\"EBEBEB\" class=\"detail\" width=\"15%\">49</td>, <td align=\"center\" bgcolor=\"EBEBEB\" class=\"detail\" width=\"15%\">D</td>] \n",
      "\n",
      "Checking rows...\n",
      "\n",
      "<tr><td bgcolor=\"white\" class=\"detail\" width=\"40%\"><a class=\"notranslate\" href=\"/senate/Senator.asp?GA=98&amp;MemberID=1911\">Pamela J. Althoff</a></td><td align=\"center\" bgcolor=\"white\" class=\"detail\" width=\"15%\"><a href=\"SenatorBills.asp?GA=98&amp;MemberID=1911\">Bills</a></td><td align=\"center\" bgcolor=\"white\" class=\"detail\" width=\"15%\"><a href=\"SenCommittees.asp?GA=98&amp;MemberID=1911\">Committees</a></td><td align=\"center\" bgcolor=\"white\" class=\"detail\" width=\"15%\">32</td><td align=\"center\" bgcolor=\"white\" class=\"detail\" width=\"15%\">R</td></tr> \n",
      "\n",
      "<tr><td bgcolor=\"white\" class=\"detail\" width=\"40%\"><a class=\"notranslate\" href=\"/senate/Senator.asp?GA=98&amp;MemberID=2035\">Patricia Van Pelt</a></td><td align=\"center\" bgcolor=\"white\" class=\"detail\" width=\"15%\"><a href=\"SenatorBills.asp?GA=98&amp;MemberID=2035\">Bills</a></td><td align=\"center\" bgcolor=\"white\" class=\"detail\" width=\"15%\"><a href=\"SenCommittees.asp?GA=98&amp;MemberID=2035\">Committees</a></td><td align=\"center\" bgcolor=\"white\" class=\"detail\" width=\"15%\">5</td><td align=\"center\" bgcolor=\"white\" class=\"detail\" width=\"15%\">D</td></tr>\n"
     ]
    }
   ],
   "source": [
    "# Bad row\n",
    "print(rows[-1].select('td.detail'), '\\n')\n",
    "\n",
    "# Good row\n",
    "print(rows[5].select('td.detail'), '\\n')\n",
    "\n",
    "# How about this?\n",
    "good_rows = [row for row in rows if row.select('td.detail')]\n",
    "\n",
    "print(\"Checking rows...\\n\")\n",
    "print(good_rows[0], '\\n')\n",
    "print(good_rows[-1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Parece que encontramos algo que ha funcionado!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Consolidarlo todo\n",
    "\n",
    "Ahora que hemos visto como obtener los datos que queremos de una fila, as√≠ como tambi√©n filtrar las filas que no queremos, vamos a consolidar todo en un bucle."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Define storage list\n",
    "members = []\n",
    "\n",
    "# Get rid of junk rows\n",
    "valid_rows = [row for row in rows if row.select('td.detail')]\n",
    "\n",
    "# Loop through all rows\n",
    "for row in valid_rows:\n",
    "    # Select only those 'td' tags with class 'detail'\n",
    "    detail_cells = row.select('td.detail')\n",
    "    # Keep only the text in each of those cells\n",
    "    row_data = [cell.text for cell in detail_cells]\n",
    "    # Collect information\n",
    "    name = row_data[0]\n",
    "    district = int(row_data[3])\n",
    "    party = row_data[4]\n",
    "    # Store in a tuple\n",
    "    senator = (name, district, party)\n",
    "    # Append to list\n",
    "    members.append(senator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "61"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Should be 61\n",
    "len(members)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vamos a ver que tenemos en `members`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('Pamela J. Althoff', 32, 'R'), ('Jason A. Barickman', 53, 'R'), ('Scott M Bennett', 52, 'D'), ('Jennifer Bertino-Tarrant', 49, 'D'), ('Daniel Biss', 9, 'D')]\n"
     ]
    }
   ],
   "source": [
    "print(members[:5])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ü•ä  Reto: Obtener elementos `href` que apunten a los proyectos de ley de los miembros  \n",
    "\n",
    "El c√≥digo anterior recupera informaci√≥n sobre:  \n",
    "\n",
    "- el nombre del senador,  \n",
    "- su n√∫mero de distrito,  \n",
    "- y su partido.  \n",
    "\n",
    "Ahora queremos obtener la URL de la lista de proyectos de ley de cada senador. Cada URL seguir√° un formato espec√≠fico.  \n",
    "\n",
    "El formato para la lista de proyectos de ley de un senador dado es:  \n",
    "\n",
    "`http://www.ilga.gov/senate/SenatorBills.asp?GA=98&MemberID=[MEMBER_ID]&Primary=True`  \n",
    "\n",
    "para obtener algo como:  \n",
    "\n",
    "`http://www.ilga.gov/senate/SenatorBills.asp?MemberID=1911&GA=98&Primary=True`  \n",
    "\n",
    "donde `MEMBER_ID=1911`.  \n",
    "\n",
    "Deber√≠as notar que, desafortunadamente, `MEMBER_ID` no se est√° extrayendo actualmente en nuestro c√≥digo de scraping.  \n",
    "\n",
    "Tu tarea inicial es modificar el c√≥digo anterior para que tambi√©n **recupere la URL completa que apunta a la p√°gina correspondiente de proyectos de ley patrocinados principalmente**, para cada miembro, y la devuelva junto con su nombre, distrito y partido.  \n",
    "\n",
    "### Consejos:  \n",
    "\n",
    "* Para hacer esto, querr√°s obtener el elemento de anclaje (`<a>`) apropiado en la fila de la tabla de cada legislador. Puedes usar nuevamente el m√©todo `.select()` en el objeto `row` dentro del bucle para hacer esto, de manera similar al comando que encuentra todas las celdas `td.detail` en la fila. Recuerda que solo queremos el enlace a los proyectos de ley del legislador, no los comit√©s ni la p√°gina de perfil del legislador.  \n",
    "* Los elementos de anclaje en el HTML se ver√°n como `<a href=\"/senate/Senator.asp/...\">Bills</a>`. La cadena en el atributo `href` contiene el **enlace relativo** que estamos buscando. Puedes acceder a un atributo de un objeto `Tag` de BeautifulSoup de la misma manera que accedes a un diccionario en Python: `anchor['attributeName']`. Consulta la <a href=\"http://www.crummy.com/software/BeautifulSoup/bs4/doc/#tag\">documentaci√≥n</a> para m√°s detalles.  \n",
    "* Hay _muchas_ formas diferentes de usar BeautifulSoup para hacer esto. Cualquier m√©todo que utilices para extraer el `href` est√° bien.  \n",
    "\n",
    "El c√≥digo ha sido parcialmente completado para ti. Compl√©talo donde dice `#YOUR CODE HERE`. Guarda la ruta en un objeto llamado `full_path`.  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Make a GET request\n",
    "req = requests.get('http://www.ilga.gov/senate/default.asp?GA=98')\n",
    "# Read the content of the server‚Äôs response\n",
    "src = req.text\n",
    "# Soup it\n",
    "soup = BeautifulSoup(src, \"lxml\")\n",
    "# Create empty list to store our data\n",
    "members = []\n",
    "\n",
    "# Returns every ‚Äòtr tr tr‚Äô css selector in the page\n",
    "rows = soup.select('tr tr tr')\n",
    "# Get rid of junk rows\n",
    "rows = [row for row in rows if row.select('td.detail')]\n",
    "\n",
    "# Loop through all rows\n",
    "for row in rows:\n",
    "    # Select only those 'td' tags with class 'detail'\n",
    "    detail_cells = row.select('td.detail') \n",
    "    # Keep only the text in each of those cells\n",
    "    row_data = [cell.text for cell in detail_cells]\n",
    "    # Collect information\n",
    "    name = row_data[0]\n",
    "    district = int(row_data[3])\n",
    "    party = row_data[4]\n",
    "\n",
    "    # YOUR CODE HERE\n",
    "    #full_path = ''\n",
    "    # Buscar el enlace a los proyectos de ley dentro de la fila\n",
    "    bill_anchor = row.select_one('td.detail a[href*=\"SenatorBills.asp\"]')\n",
    "    \n",
    "    # Extraer el 'href' si existe, y construir la URL completa\n",
    "    if bill_anchor:\n",
    "        relative_path = bill_anchor['href']\n",
    "        full_path = f\"http://www.ilga.gov{relative_path}\"\n",
    "    else:\n",
    "        full_path = ''\n",
    "\n",
    "    # Store in a tuple\n",
    "    senator = (name, district, party, full_path)\n",
    "    # Append to list\n",
    "    members.append(senator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('Pamela J. Althoff',\n",
       "  32,\n",
       "  'R',\n",
       "  'http://www.ilga.govSenatorBills.asp?GA=98&MemberID=1911'),\n",
       " ('Jason A. Barickman',\n",
       "  53,\n",
       "  'R',\n",
       "  'http://www.ilga.govSenatorBills.asp?GA=98&MemberID=2018'),\n",
       " ('Scott M Bennett',\n",
       "  52,\n",
       "  'D',\n",
       "  'http://www.ilga.govSenatorBills.asp?GA=98&MemberID=2272'),\n",
       " ('Jennifer Bertino-Tarrant',\n",
       "  49,\n",
       "  'D',\n",
       "  'http://www.ilga.govSenatorBills.asp?GA=98&MemberID=2022'),\n",
       " ('Daniel Biss',\n",
       "  9,\n",
       "  'D',\n",
       "  'http://www.ilga.govSenatorBills.asp?GA=98&MemberID=2020')]"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Uncomment to test \n",
    "members[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ü•ä  Reto: Modulariza tu c√≥digo  \n",
    "\n",
    "Convierte el c√≥digo anterior en una funci√≥n que acepte una URL, extraiga los senadores de esa URL y devuelva una lista de tuplas que contengan informaci√≥n sobre cada senador.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# YOUR CODE HERE\n",
    "def get_members(url):\n",
    "    # Hacer la solicitud GET\n",
    "    req = requests.get(url)\n",
    "    # Leer el contenido de la respuesta del servidor\n",
    "    src = req.text\n",
    "    # Analizar con BeautifulSoup\n",
    "    soup = BeautifulSoup(src, \"lxml\")\n",
    "\n",
    "    # Crear una lista vac√≠a para almacenar los datos\n",
    "    members = []\n",
    "\n",
    "    # Obtener todas las filas 'tr tr tr' que contienen datos\n",
    "    rows = soup.select('tr tr tr')\n",
    "    # Filtrar las filas basura\n",
    "    rows = [row for row in rows if row.select('td.detail')]\n",
    "\n",
    "    # Iterar sobre cada fila\n",
    "    for row in rows:\n",
    "        # Seleccionar solo las celdas 'td' con clase 'detail'\n",
    "        detail_cells = row.select('td.detail')  \n",
    "        # Extraer el texto de cada celda\n",
    "        row_data = [cell.text.strip() for cell in detail_cells]\n",
    "\n",
    "        # Extraer informaci√≥n relevante\n",
    "        name = row_data[0]\n",
    "        district = int(row_data[3])\n",
    "        party = row_data[4]\n",
    "\n",
    "        # Buscar el enlace a los proyectos de ley dentro de la fila\n",
    "        bill_anchor = row.select_one('td.detail a[href*=\"SenatorBills.asp\"]')\n",
    "\n",
    "        # Extraer el 'href' si existe, y construir la URL completa\n",
    "        if bill_anchor:\n",
    "            relative_path = bill_anchor['href']\n",
    "            full_path = f\"http://www.ilga.gov{relative_path}\"\n",
    "        else:\n",
    "            full_path = ''\n",
    "\n",
    "        # Almacenar en una tupla\n",
    "        senator = (name, district, party, full_path)\n",
    "        # Agregar a la lista\n",
    "        members.append(senator)\n",
    "\n",
    "    return members\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "61"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Test your code\n",
    "url = 'http://www.ilga.gov/senate/default.asp?GA=98'\n",
    "senate_members = get_members(url)\n",
    "len(senate_members)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ü•ä Reto para llevar a casa: Escribir una funci√≥n de scraping  \n",
    "\n",
    "Queremos extraer informaci√≥n de las p√°ginas web correspondientes a los proyectos de ley patrocinados por cada legislador.  \n",
    "\n",
    "Escribe una funci√≥n llamada `get_bills(url)` para analizar una URL de proyectos de ley dada. Esto implicar√°:  \n",
    "\n",
    "- hacer una solicitud a la URL usando la librer√≠a <a href=\"http://docs.python-requests.org/en/latest/\">`requests`</a>  \n",
    "- usar las funciones de la librer√≠a `BeautifulSoup` para encontrar todos los elementos `<td>` con la clase `billlist`  \n",
    "- devolver una _lista_ de tuplas, cada una con:  \n",
    "    - la descripci√≥n (2¬™ columna)  \n",
    "    - la c√°mara (S o H) (3¬™ columna)  \n",
    "    - la √∫ltima acci√≥n (4¬™ columna)  \n",
    "    - la fecha de la √∫ltima acci√≥n (5¬™ columna)  \n",
    "\n",
    "Esta funci√≥n ha sido parcialmente completada. Compl√©tala.  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (3384773414.py, line 8)",
     "output_type": "error",
     "traceback": [
      "  \u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[39]\u001b[39m\u001b[32m, line 8\u001b[39m\n\u001b[31m    \u001b[39m\u001b[31mbill_id =\u001b[39m\n             ^\n\u001b[31mSyntaxError\u001b[39m\u001b[31m:\u001b[39m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "def get_bills(url):\n",
    "    src = requests.get(url).text\n",
    "    soup = BeautifulSoup(src)\n",
    "    rows = soup.select('tr')\n",
    "    bills = []\n",
    "    for row in rows:\n",
    "        # YOUR CODE HERE\n",
    "        bill_id =\n",
    "        description =\n",
    "        chamber =\n",
    "        last_action =\n",
    "        last_action_date =\n",
    "        bill = (bill_id, description, chamber, last_action, last_action_date)\n",
    "        bills.append(bill)\n",
    "    return bills"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Uncomment to test your code\n",
    "# test_url = senate_members[0][3]\n",
    "# get_bills(test_url)[0:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Scrape All Bills\n",
    "\n",
    "Finally, create a dictionary `bills_dict` which maps a district number (the key) onto a list of bills (the value) coming from that district. You can do this by looping over all of the senate members in `members_dict` and calling `get_bills()` for each of their associated bill URLs.\n",
    "\n",
    "**NOTE:** please call the function `time.sleep(1)` for each iteration of the loop, so that we don't destroy the state's web site."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# YOUR CODE HERE\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Uncomment to test your code\n",
    "# bills_dict[52]"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
